#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆé£Ÿç‰©ç†±é‡æå–å™¨
åªæå–é£Ÿç‰©åç¨±å’Œç†±é‡è³‡è¨Š
"""

import requests
from bs4 import BeautifulSoup
import json
import time
import csv
import os
from datetime import datetime
import logging
import re
from typing import List, Dict, Optional

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleFoodCaloriesExtractor:
    """ç°¡åŒ–ç‰ˆé£Ÿç‰©ç†±é‡æå–å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        self.base_url = "https://consumer.fda.gov.tw/Food/TFND.aspx"
        self.session = requests.Session()
        
        # è¨­å®šè«‹æ±‚æ¨™é ­
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
    
    def get_main_page(self) -> Optional[BeautifulSoup]:
        """ç²å–ä¸»é é¢"""
        try:
            params = {'nodeID': '178'}
            response = self.session.get(self.base_url, params=params)
            response.raise_for_status()
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')
            return soup
        except Exception as e:
            logger.error(f"ç²å–ä¸»é é¢å¤±æ•—: {e}")
            return None
    
    def extract_viewstate(self, soup: BeautifulSoup) -> Dict[str, str]:
        """æå– ASP.NET çš„ ViewState åƒæ•¸"""
        viewstate_data = {}
        
        viewstate = soup.find('input', {'name': '__VIEWSTATE'})
        if viewstate:
            viewstate_data['__VIEWSTATE'] = viewstate.get('value', '')
        
        viewstategenerator = soup.find('input', {'name': '__VIEWSTATEGENERATOR'})
        if viewstategenerator:
            viewstate_data['__VIEWSTATEGENERATOR'] = viewstategenerator.get('value', '')
        
        eventvalidation = soup.find('input', {'name': '__EVENTVALIDATION'})
        if eventvalidation:
            viewstate_data['__EVENTVALIDATION'] = eventvalidation.get('value', '')
        
        return viewstate_data
    
    def search_foods(self, category: str = '', keyword: str = '', page: int = 1) -> List[Dict]:
        """æœå°‹é£Ÿå“è³‡æ–™"""
        try:
            soup = self.get_main_page()
            if not soup:
                return []
            
            viewstate_data = self.extract_viewstate(soup)
            
            search_data = {
                '__VIEWSTATE': viewstate_data.get('__VIEWSTATE', ''),
                '__VIEWSTATEGENERATOR': viewstate_data.get('__VIEWSTATEGENERATOR', ''),
                '__EVENTVALIDATION': viewstate_data.get('__EVENTVALIDATION', ''),
                '__EVENTTARGET': '',
                '__EVENTARGUMENT': '',
                'ctl00$ContentPlaceHolder1$DropDownList1': category,
                'ctl00$ContentPlaceHolder1$TextBox1': keyword,
                'ctl00$ContentPlaceHolder1$Button1': 'æŸ¥è©¢'
            }
            
            if page > 1:
                search_data['__EVENTTARGET'] = 'ctl00$ContentPlaceHolder1$GridView1'
                search_data['__EVENTARGUMENT'] = f'Page${page}'
            
            response = self.session.post(self.base_url, data=search_data, params={'nodeID': '178'})
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return self.parse_search_results(soup)
            
        except Exception as e:
            logger.error(f"æœå°‹é£Ÿå“è³‡æ–™å¤±æ•—: {e}")
            return []
    
    def parse_search_results(self, soup: BeautifulSoup) -> List[Dict]:
        """è§£ææœå°‹çµæœ"""
        results = []
        
        try:
            table = soup.find('table', {'id': 'ctl00_ContentPlaceHolder1_GridView1'})
            if not table:
                return results
            
            rows = table.find_all('tr')[1:]  # è·³éæ¨™é¡Œè¡Œ
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 5:
                    link_cell = cells[1].find('a')
                    detail_url = None
                    if link_cell:
                        detail_url = 'https://consumer.fda.gov.tw/Food/' + link_cell.get('href', '')
                    
                    food_data = {
                        'food_name': cells[1].get_text(strip=True),
                        'detail_url': detail_url
                    }
                    
                    results.append(food_data)
            
        except Exception as e:
            logger.error(f"è§£ææœå°‹çµæœå¤±æ•—: {e}")
        
        return results
    
    def get_food_calories(self, detail_url: str) -> Optional[Dict]:
        """ç²å–é£Ÿå“ç†±é‡è³‡è¨Š"""
        try:
            response = self.session.get(detail_url)
            response.raise_for_status()
            response.encoding = 'utf-8'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            return self.extract_calories(soup)
            
        except Exception as e:
            logger.error(f"ç²å–é£Ÿå“ç†±é‡å¤±æ•—: {e}")
            return None
    
    def extract_calories(self, soup: BeautifulSoup) -> Optional[Dict]:
        """æå–ç†±é‡è³‡è¨Š"""
        try:
            calories = None
            
            # å°‹æ‰¾æ‰€æœ‰è¡¨æ ¼
            tables = soup.find_all('table')
            
            for table in tables:
                rows = table.find_all('tr')
                
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        key = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        
                        # å°‹æ‰¾ç†±é‡ç›¸é—œæ¬„ä½
                        if 'ç†±é‡' in key and value:
                            # æå–æ•¸å­—
                            calories_match = re.search(r'(\d+(?:\.\d+)?)', value)
                            if calories_match:
                                calories = float(calories_match.group(1))
                                break
                
                if calories is not None:
                    break
            
            return {'calories': calories} if calories is not None else None
            
        except Exception as e:
            logger.error(f"æå–ç†±é‡å¤±æ•—: {e}")
            return None
    
    def scrape_food_calories(self, max_pages: int = 10, max_details: int = 50) -> List[Dict]:
        """æŠ“å–é£Ÿç‰©ç†±é‡è³‡æ–™"""
        all_foods = []
        
        try:
            logger.info("é–‹å§‹æŠ“å–é£Ÿç‰©åŸºæœ¬è³‡æ–™...")
            
            # é€é æŠ“å–
            for page in range(1, max_pages + 1):
                logger.info(f"æ­£åœ¨æŠ“å–ç¬¬ {page} é ...")
                
                foods = self.search_foods(page=page)
                if not foods:
                    logger.info(f"ç¬¬ {page} é æ²’æœ‰è³‡æ–™ï¼Œåœæ­¢æŠ“å–")
                    break
                
                all_foods.extend(foods)
                time.sleep(1)  # é¿å…è«‹æ±‚éæ–¼é »ç¹
            
            logger.info(f"ç¸½å…±æŠ“å–åˆ° {len(all_foods)} ç¨®é£Ÿç‰©")
            
            # æŠ“å–ç†±é‡è³‡è¨Š
            logger.info(f"é–‹å§‹æŠ“å– {min(len(all_foods), max_details)} ç¨®é£Ÿç‰©çš„ç†±é‡è³‡è¨Š...")
            
            foods_with_calories = []
            for i, food in enumerate(all_foods[:max_details]):
                if food.get('detail_url'):
                    logger.info(f"æ­£åœ¨æŠ“å– {food['food_name']} çš„ç†±é‡...")
                    
                    calories_info = self.get_food_calories(food['detail_url'])
                    if calories_info and calories_info['calories'] is not None:
                        food['calories'] = calories_info['calories']
                        foods_with_calories.append(food)
                    
                    time.sleep(2)  # é¿å…è«‹æ±‚éæ–¼é »ç¹
            
            logger.info(f"æˆåŠŸæŠ“å– {len(foods_with_calories)} ç¨®é£Ÿç‰©çš„ç†±é‡è³‡è¨Š")
            return foods_with_calories
            
        except Exception as e:
            logger.error(f"æŠ“å–é£Ÿç‰©ç†±é‡è³‡æ–™å¤±æ•—: {e}")
            return all_foods
    
    def save_to_json(self, data: List[Dict], filename: str):
        """å„²å­˜è³‡æ–™ç‚º JSON æ ¼å¼"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"è³‡æ–™å·²å„²å­˜è‡³ {filename}")
            
        except Exception as e:
            logger.error(f"å„²å­˜ JSON æª”æ¡ˆå¤±æ•—: {e}")
    
    def save_to_csv(self, data: List[Dict], filename: str):
        """å„²å­˜è³‡æ–™ç‚º CSV æ ¼å¼"""
        try:
            if not data:
                return
            
            fieldnames = ['food_name', 'calories']
            
            with open(filename, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
            
            logger.info(f"è³‡æ–™å·²å„²å­˜è‡³ {filename}")
            
        except Exception as e:
            logger.error(f"å„²å­˜ CSV æª”æ¡ˆå¤±æ•—: {e}")
    
    def create_calories_database(self, foods: List[Dict]) -> Dict:
        """å‰µå»ºç†±é‡è³‡æ–™åº«"""
        calories_db = {}
        
        try:
            for food in foods:
                food_name = food.get('food_name', '').lower()
                calories = food.get('calories')
                
                if food_name and calories is not None:
                    calories_db[food_name] = {
                        'calories': calories,
                        'original_name': food.get('food_name', ''),
                        'source': 'FDA_TW'
                    }
            
            logger.info(f"æˆåŠŸå»ºç«‹ç†±é‡è³‡æ–™åº«ï¼ŒåŒ…å« {len(calories_db)} ç¨®é£Ÿç‰©")
            return calories_db
            
        except Exception as e:
            logger.error(f"å»ºç«‹ç†±é‡è³‡æ–™åº«å¤±æ•—: {e}")
            return calories_db

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ½ï¸ ç°¡åŒ–ç‰ˆé£Ÿç‰©ç†±é‡æå–å™¨")
    print("=" * 40)
    print("ğŸ“‹ åªæå–é£Ÿç‰©åç¨±å’Œç†±é‡è³‡è¨Š")
    print("=" * 40)
    
    extractor = SimpleFoodCaloriesExtractor()
    
    # æŠ“å–è³‡æ–™
    print("ğŸ“‹ æŠ“å–é£Ÿç‰©ç†±é‡è³‡æ–™...")
    foods = extractor.scrape_food_calories(max_pages=5, max_details=20)  # é™åˆ¶æ•¸é‡é¿å…éåº¦è«‹æ±‚
    
    if foods:
        # å„²å­˜è³‡æ–™
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å„²å­˜å®Œæ•´è³‡æ–™
        extractor.save_to_json(foods, f"food_calories_{timestamp}.json")
        extractor.save_to_csv(foods, f"food_calories_{timestamp}.csv")
        
        # å‰µå»ºç†±é‡è³‡æ–™åº«
        calories_db = extractor.create_calories_database(foods)
        if calories_db:
            extractor.save_to_json(calories_db, f"calories_database_{timestamp}.json")
        
        # é¡¯ç¤ºçµæœ
        print(f"\nâœ… æˆåŠŸæå– {len(foods)} ç¨®é£Ÿç‰©çš„ç†±é‡è³‡è¨Š")
        print("\nğŸ“Š å‰ 10 ç¨®é£Ÿç‰©ç†±é‡:")
        for i, food in enumerate(foods[:10]):
            calories = food.get('calories', 'N/A')
            print(f"  {i+1:2d}. {food['food_name']}: {calories} å¡è·¯é‡Œ")
        
        print(f"\nğŸ’¾ æª”æ¡ˆå·²å„²å­˜:")
        print(f"   - food_calories_{timestamp}.json")
        print(f"   - food_calories_{timestamp}.csv")
        print(f"   - calories_database_{timestamp}.json")
        
    else:
        print("âŒ æœªæŠ“å–åˆ°ä»»ä½•è³‡æ–™")

if __name__ == "__main__":
    main() 